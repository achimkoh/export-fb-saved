{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 3.5.3\n",
    "\n",
    "import time, random\n",
    "from selenium import webdriver\n",
    "from urllib.parse import urlparse, parse_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.facebook.com/saved'\n",
    "browser = webdriver.PhantomJS()\n",
    "# browser = webdriver.Chrome()\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_css_selector('input#email').send_keys('') # Login email here\n",
    "browser.find_element_by_css_selector('input#pass').send_keys('') # Login password here\n",
    "browser.find_element_by_css_selector('button#loginbutton').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll to the bottom of the page, until we reach the end and the feed stops loading \n",
    "previousScroll = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "# Try multiple times, in case previous attempt did not load due to network delay \n",
    "for j in range(0, 3):\n",
    "\tbrowser.execute_script(\"window.scrollTo(0, 0);\")\n",
    "\ttime.sleep(random.random()) # This probably doesn't need to be random, I just don't want FB to notice I'm scraping\n",
    "\twhile True:\n",
    "\t\tbrowser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\t\ttime.sleep(2 + random.random())\n",
    "\t\tif previousScroll != browser.execute_script(\"return document.body.scrollHeight;\"):\n",
    "\t\t\tpreviousScroll = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\tprint(\"I think I reached the bottom. Will try to scroll down \" + str(2-j) + \" more time(s)\")\n",
    "\ttime.sleep(2 + random.random())\n",
    "\n",
    "print(\"Yup, that's it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser.save_screenshot('now.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from Oscar Cassetti's code \n",
    "# https://www.quora.com/How-can-I-export-all-my-Facebook-saved-read-it-later-links\n",
    "\n",
    "links = browser.find_elements_by_css_selector('._4bl9._5yjp') # this is the div with the links\n",
    "\n",
    "for link in links:\n",
    "    link_url = link.find_element_by_css_selector('a').get_attribute('href')\n",
    "    # sometimes the url gets dirty FB redirection. Clean it up:\n",
    "    o = urlparse(link_url)\n",
    "    try:\n",
    "        if parse_qs(o.query)['u']:\n",
    "            link_url = parse_qs(o.query)['u'][0]\n",
    "    except:\n",
    "        True # Not an elegant exception handling... but whatever! This only needs to work once.\n",
    "\n",
    "    link_description = link.text.replace('\\n', '|').replace(';', '|') # 1 item per row; semicolon will divide column  \n",
    "    \n",
    "    with open('saved.txt', 'a') as f:\n",
    "        f.write(link_url+' ; '+link_description+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
